{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Logit (LASSO) on S&P 500 Panel Data\n",
    "\n",
    "This notebook builds a **panel dataset** (all S&P 500 firms together) and explains:\n",
    "- `up`\n",
    "- `same`\n",
    "- `down`\n",
    "\n",
    "for daily returns using **Multinomial Logistic Regression with L1 regularization (LASSO)**.\n",
    "\n",
    "## Workflow\n",
    "1. Load consolidated panel `ConstructionDataset/all_companies_features.csv`.\n",
    "2. Left join `stock_sectors.csv` and one-hot encode sector.\n",
    "3. Keep observations from **2024-11-01 to 2025-10-31**.\n",
    "4. Use **10 months for train/CV** and **last 2 months for out-of-sample validation**.\n",
    "5. Choose a symmetric threshold around zero based on train percentiles to balance classes.\n",
    "6. Train multinomial logit with LASSO using `TimeSeriesSplit(n_splits=5)`.\n",
    "7. Save metrics, predictions, coefficients, and plots to `MultinomialLogit/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    balanced_accuracy_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    ")\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: c:\\Users\\jorge\\OneDrive\\Documentos\\Data 606\\Project\n",
      "Output dir: c:\\Users\\jorge\\OneDrive\\Documentos\\Data 606\\Project\\MultinomialLogit\\run_20260212_043813\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ROOT = Path.cwd()\n",
    "if not (PROJECT_ROOT / \"ConstructionDataset\" / \"all_companies_features.csv\").exists():\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent\n",
    "\n",
    "PANEL_PATH = PROJECT_ROOT / \"ConstructionDataset\" / \"all_companies_features.csv\"\n",
    "SECTOR_PATH = PROJECT_ROOT / \"stock_sectors.csv\"\n",
    "OUTPUT_BASE = PROJECT_ROOT / \"MultinomialLogit\"\n",
    "\n",
    "if not PANEL_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Panel dataset not found: {PANEL_PATH}\")\n",
    "\n",
    "START_DATE = pd.Timestamp(\"2024-11-01\")\n",
    "END_DATE = pd.Timestamp(\"2025-10-31\")\n",
    "TRAIN_START = pd.Timestamp(\"2024-11-01\")\n",
    "TRAIN_END = pd.Timestamp(\"2025-08-31\")\n",
    "VAL_START = pd.Timestamp(\"2025-09-01\")\n",
    "VAL_END = pd.Timestamp(\"2025-10-31\")\n",
    "\n",
    "NUMERIC_FEATURES = [\n",
    "    \"Return_Lag1\", \"Return_Lag2\", \"Return_Lag3\", \"Return_Lag5\", \"Return_Lag10\", \"Return_Lag20\",\n",
    "    \"Sentiment_Lag1\", \"Sentiment_Lag2\", \"Sentiment_Lag3\", \"Sentiment_Lag5\", \"Sentiment_Lag10\", \"Sentiment_Lag20\",\n",
    "    \"Sentiment_Lag1_squared\", \"Sentiment_Lag1_cubic\",\n",
    "    \"VIX_Lag1\", \"VIX_Lag2\", \"VIX_Lag3\", \"VIX_Lag5\", \"VIX_Lag10\", \"VIX_Lag20\",\n",
    "    \"roe\", \"roa\", \"op_margin\", \"debt_to_equity\", \"liquidity_ratio\", \"current_ratio\",\n",
    "    \"free_cf_margin\", \"revenue_growth\", \"ocf_to_assets\",\n",
    "    \"GDP_GDP_SA_PC_QOQ\", \"GDP_GDP_SA_PC_YOY\", \"GDP_GDP_NSA_PC_QOQ\", \"GDP_GDP_NSA_PC_YOY\",\n",
    "    \"IPI_IPI\", \"IPI_IPI_YOY\", \"IPI_IPI_QOQ\", \"IPI_IPI_SA\", \"IPI_IPI_SA_YOY\", \"IPI_IPI_SA_QOQ\",\n",
    "    \"UNEMP_UNRATE\", \"UNEMP_UNRATE_PC1\", \"UNEMP_UNRATE_PCH\",\n",
    "    \"UNEMP_UNRATENSA\", \"UNEMP_UNRATENSA_PC1\", \"UNEMP_UNRATENSA_PCH\",\n",
    "]\n",
    "\n",
    "CATEGORICAL_FEATURES = [\"ticker\", \"sector\"]  # ticker FE + sector FE\n",
    "TARGET_COL = \"Return_Status\"\n",
    "RETURN_COL = \"Return\"\n",
    "\n",
    "N_SPLITS = 5\n",
    "C_GRID = np.logspace(-2, 1.5, 8)\n",
    "MAX_ITER = 3000\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "RUN_TAG = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "OUTPUT_DIR = OUTPUT_BASE / f\"run_{RUN_TAG}\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Project root:\", PROJECT_ROOT)\n",
    "print(\"Panel path:\", PANEL_PATH)\n",
    "print(\"Output dir:\", OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Helper functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_ohe():\n",
    "    try:\n",
    "        return OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True)\n",
    "    except TypeError:\n",
    "        return OneHotEncoder(handle_unknown=\"ignore\", sparse=True)\n",
    "\n",
    "\n",
    "def load_panel_feature_data(data_path: Path, required_cols: list[str]) -> pd.DataFrame:\n",
    "    if not data_path.exists():\n",
    "        raise FileNotFoundError(f\"Panel dataset not found: {data_path}\")\n",
    "\n",
    "    panel = pd.read_csv(data_path)\n",
    "\n",
    "    derived_cols = {\"Sentiment_Lag1_squared\", \"Sentiment_Lag1_cubic\"}\n",
    "    needed = [\"Date\", \"ticker\", RETURN_COL] + [c for c in required_cols if c not in derived_cols]\n",
    "    missing = [c for c in needed if c not in panel.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"{data_path.name} missing columns: {missing}\")\n",
    "\n",
    "    panel = panel[needed].copy()\n",
    "    panel[\"ticker\"] = panel[\"ticker\"].astype(str).str.strip()\n",
    "    panel[\"Sentiment_Lag1\"] = pd.to_numeric(panel[\"Sentiment_Lag1\"], errors=\"coerce\")\n",
    "    panel[\"Sentiment_Lag1_squared\"] = panel[\"Sentiment_Lag1\"] ** 2\n",
    "    panel[\"Sentiment_Lag1_cubic\"] = panel[\"Sentiment_Lag1\"] ** 3\n",
    "    panel[\"Date\"] = pd.to_datetime(panel[\"Date\"], errors=\"coerce\")\n",
    "\n",
    "    panel = panel.dropna(subset=[\"Date\", \"ticker\"])\n",
    "    return panel\n",
    "\n",
    "\n",
    "def make_return_status(ret: pd.Series, thr: float) -> pd.Series:\n",
    "    y = pd.Series(index=ret.index, dtype=\"object\")\n",
    "    y[ret > thr] = \"up\"\n",
    "    y[ret < -thr] = \"down\"\n",
    "    y[ret.between(-thr, thr, inclusive=\"both\")] = \"same\"\n",
    "    return y\n",
    "\n",
    "\n",
    "def choose_balanced_symmetric_threshold(train_returns: pd.Series, percentiles: np.ndarray):\n",
    "    train_returns = train_returns.dropna()\n",
    "    abs_ret = train_returns.abs()\n",
    "    rows = []\n",
    "\n",
    "    for p in percentiles:\n",
    "        thr = np.percentile(abs_ret, p)\n",
    "        labels = make_return_status(train_returns, thr)\n",
    "        share = labels.value_counts(normalize=True).reindex([\"down\", \"same\", \"up\"], fill_value=0.0)\n",
    "        imbalance = ((share - (1.0 / 3.0)) ** 2).sum()\n",
    "\n",
    "        rows.append(\n",
    "            {\n",
    "                \"percentile\": float(p),\n",
    "                \"threshold\": float(thr),\n",
    "                \"share_down\": float(share[\"down\"]),\n",
    "                \"share_same\": float(share[\"same\"]),\n",
    "                \"share_up\": float(share[\"up\"]),\n",
    "                \"imbalance_score\": float(imbalance),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    grid_df = pd.DataFrame(rows).sort_values([\"imbalance_score\", \"percentile\"]).reset_index(drop=True)\n",
    "    best_thr = float(grid_df.loc[0, \"threshold\"])\n",
    "    return best_thr, grid_df\n",
    "\n",
    "\n",
    "def time_series_splits_by_date(dates: pd.Series, n_splits: int = 5):\n",
    "    d = pd.to_datetime(dates)\n",
    "    unique_dates = np.array(sorted(pd.Series(d.unique())))\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "    for fold, (tr_d, te_d) in enumerate(tscv.split(unique_dates), start=1):\n",
    "        tr_dates = set(unique_dates[tr_d])\n",
    "        te_dates = set(unique_dates[te_d])\n",
    "\n",
    "        tr_idx = np.where(d.isin(tr_dates))[0]\n",
    "        te_idx = np.where(d.isin(te_dates))[0]\n",
    "        yield fold, tr_idx, te_idx\n",
    "\n",
    "\n",
    "def metric_frame(y_true, y_pred, split_name: str) -> pd.DataFrame:\n",
    "    return pd.DataFrame(\n",
    "        [\n",
    "            {\n",
    "                \"split\": split_name,\n",
    "                \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "                \"balanced_accuracy\": balanced_accuracy_score(y_true, y_pred),\n",
    "                \"f1_macro\": f1_score(y_true, y_pred, average=\"macro\", zero_division=0),\n",
    "                \"f1_weighted\": f1_score(y_true, y_pred, average=\"weighted\", zero_division=0),\n",
    "                \"n_samples\": len(y_true),\n",
    "            }\n",
    "        ]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Build panel + left join sectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Panel shape: (125750, 47)\n",
      "Tickers: 503 | Sectors: 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Return</th>\n",
       "      <th>Return_Lag1</th>\n",
       "      <th>Return_Lag2</th>\n",
       "      <th>Return_Lag3</th>\n",
       "      <th>Return_Lag5</th>\n",
       "      <th>Return_Lag10</th>\n",
       "      <th>Return_Lag20</th>\n",
       "      <th>Sentiment_Lag1</th>\n",
       "      <th>Sentiment_Lag2</th>\n",
       "      <th>...</th>\n",
       "      <th>IPI_IPI_SA_YOY</th>\n",
       "      <th>IPI_IPI_SA_QOQ</th>\n",
       "      <th>UNEMP_UNRATE</th>\n",
       "      <th>UNEMP_UNRATE_PC1</th>\n",
       "      <th>UNEMP_UNRATE_PCH</th>\n",
       "      <th>UNEMP_UNRATENSA</th>\n",
       "      <th>UNEMP_UNRATENSA_PC1</th>\n",
       "      <th>UNEMP_UNRATENSA_PCH</th>\n",
       "      <th>ticker</th>\n",
       "      <th>sector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-11-01</td>\n",
       "      <td>0.050341</td>\n",
       "      <td>-0.008974</td>\n",
       "      <td>0.001981</td>\n",
       "      <td>-0.002357</td>\n",
       "      <td>-0.003826</td>\n",
       "      <td>0.010261</td>\n",
       "      <td>0.002906</td>\n",
       "      <td>-0.2150</td>\n",
       "      <td>-0.3330</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.28793</td>\n",
       "      <td>-0.30036</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2.38095</td>\n",
       "      <td>2.38095</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2.27273</td>\n",
       "      <td>-2.17391</td>\n",
       "      <td>A</td>\n",
       "      <td>Healthcare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-11-01</td>\n",
       "      <td>-0.013280</td>\n",
       "      <td>-0.018209</td>\n",
       "      <td>-0.015278</td>\n",
       "      <td>0.001157</td>\n",
       "      <td>0.003643</td>\n",
       "      <td>0.012277</td>\n",
       "      <td>0.005007</td>\n",
       "      <td>-0.0011</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.28793</td>\n",
       "      <td>-0.30036</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2.38095</td>\n",
       "      <td>2.38095</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2.27273</td>\n",
       "      <td>-2.17391</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-11-01</td>\n",
       "      <td>-0.001570</td>\n",
       "      <td>0.011762</td>\n",
       "      <td>0.063605</td>\n",
       "      <td>-0.001213</td>\n",
       "      <td>-0.009491</td>\n",
       "      <td>0.001538</td>\n",
       "      <td>-0.005935</td>\n",
       "      <td>0.7737</td>\n",
       "      <td>0.0261</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.28793</td>\n",
       "      <td>-0.30036</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2.38095</td>\n",
       "      <td>2.38095</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2.27273</td>\n",
       "      <td>-2.17391</td>\n",
       "      <td>ABBV</td>\n",
       "      <td>Healthcare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-11-01</td>\n",
       "      <td>0.012390</td>\n",
       "      <td>-0.012528</td>\n",
       "      <td>-0.009290</td>\n",
       "      <td>0.014730</td>\n",
       "      <td>0.013785</td>\n",
       "      <td>0.003161</td>\n",
       "      <td>0.036396</td>\n",
       "      <td>-0.0055</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.28793</td>\n",
       "      <td>-0.30036</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2.38095</td>\n",
       "      <td>2.38095</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2.27273</td>\n",
       "      <td>-2.17391</td>\n",
       "      <td>ABNB</td>\n",
       "      <td>Consumer Cyclical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-11-01</td>\n",
       "      <td>0.046132</td>\n",
       "      <td>-0.009436</td>\n",
       "      <td>0.009259</td>\n",
       "      <td>-0.005874</td>\n",
       "      <td>-0.019907</td>\n",
       "      <td>0.012724</td>\n",
       "      <td>0.003653</td>\n",
       "      <td>0.0557</td>\n",
       "      <td>-0.1955</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.28793</td>\n",
       "      <td>-0.30036</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2.38095</td>\n",
       "      <td>2.38095</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2.27273</td>\n",
       "      <td>-2.17391</td>\n",
       "      <td>ABT</td>\n",
       "      <td>Healthcare</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date    Return  Return_Lag1  Return_Lag2  Return_Lag3  Return_Lag5  \\\n",
       "0 2024-11-01  0.050341    -0.008974     0.001981    -0.002357    -0.003826   \n",
       "1 2024-11-01 -0.013280    -0.018209    -0.015278     0.001157     0.003643   \n",
       "2 2024-11-01 -0.001570     0.011762     0.063605    -0.001213    -0.009491   \n",
       "3 2024-11-01  0.012390    -0.012528    -0.009290     0.014730     0.013785   \n",
       "4 2024-11-01  0.046132    -0.009436     0.009259    -0.005874    -0.019907   \n",
       "\n",
       "   Return_Lag10  Return_Lag20  Sentiment_Lag1  Sentiment_Lag2  ...  \\\n",
       "0      0.010261      0.002906         -0.2150         -0.3330  ...   \n",
       "1      0.012277      0.005007         -0.0011          0.0016  ...   \n",
       "2      0.001538     -0.005935          0.7737          0.0261  ...   \n",
       "3      0.003161      0.036396         -0.0055          0.0148  ...   \n",
       "4      0.012724      0.003653          0.0557         -0.1955  ...   \n",
       "\n",
       "   IPI_IPI_SA_YOY  IPI_IPI_SA_QOQ  UNEMP_UNRATE  UNEMP_UNRATE_PC1  \\\n",
       "0        -0.28793        -0.30036           4.3           2.38095   \n",
       "1        -0.28793        -0.30036           4.3           2.38095   \n",
       "2        -0.28793        -0.30036           4.3           2.38095   \n",
       "3        -0.28793        -0.30036           4.3           2.38095   \n",
       "4        -0.28793        -0.30036           4.3           2.38095   \n",
       "\n",
       "   UNEMP_UNRATE_PCH  UNEMP_UNRATENSA  UNEMP_UNRATENSA_PC1  \\\n",
       "0           2.38095              4.5              2.27273   \n",
       "1           2.38095              4.5              2.27273   \n",
       "2           2.38095              4.5              2.27273   \n",
       "3           2.38095              4.5              2.27273   \n",
       "4           2.38095              4.5              2.27273   \n",
       "\n",
       "   UNEMP_UNRATENSA_PCH  ticker             sector  \n",
       "0             -2.17391       A         Healthcare  \n",
       "1             -2.17391    AAPL         Technology  \n",
       "2             -2.17391    ABBV         Healthcare  \n",
       "3             -2.17391    ABNB  Consumer Cyclical  \n",
       "4             -2.17391     ABT         Healthcare  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panel = load_panel_feature_data(PANEL_PATH, NUMERIC_FEATURES)\n",
    "sectors = pd.read_csv(SECTOR_PATH)[[\"ticker\", \"sector\"]].copy()\n",
    "panel = panel.merge(sectors, on=\"ticker\", how=\"left\")\n",
    "\n",
    "panel = panel[(panel[\"Date\"] >= START_DATE) & (panel[\"Date\"] <= END_DATE)].copy()\n",
    "panel = panel.sort_values([\"Date\", \"ticker\"]).reset_index(drop=True)\n",
    "\n",
    "print(\"Panel shape:\", panel.shape)\n",
    "print(\"Tickers:\", panel[\"ticker\"].nunique(), \"| Sectors:\", panel[\"sector\"].nunique())\n",
    "panel.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Time split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rows: 103618 | 2024-11-01 to 2025-08-29\n",
      "Val rows  : 22132 | 2025-09-02 to 2025-10-31\n"
     ]
    }
   ],
   "source": [
    "train_df = panel[(panel[\"Date\"] >= TRAIN_START) & (panel[\"Date\"] <= TRAIN_END)].copy()\n",
    "val_df = panel[(panel[\"Date\"] >= VAL_START) & (panel[\"Date\"] <= VAL_END)].copy()\n",
    "\n",
    "print(\"Train rows:\", len(train_df), \"|\", train_df[\"Date\"].min().date(), \"to\", train_df[\"Date\"].max().date())\n",
    "print(\"Val rows  :\", len(val_df), \"|\", val_df[\"Date\"].min().date(), \"to\", val_df[\"Date\"].max().date())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Symmetric threshold selection (train only)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected threshold: ±0.006007 (0.601%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>percentile</th>\n",
       "      <th>threshold</th>\n",
       "      <th>share_down</th>\n",
       "      <th>share_same</th>\n",
       "      <th>share_up</th>\n",
       "      <th>imbalance_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33.0</td>\n",
       "      <td>0.006007</td>\n",
       "      <td>0.315650</td>\n",
       "      <td>0.330001</td>\n",
       "      <td>0.354350</td>\n",
       "      <td>0.000765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34.0</td>\n",
       "      <td>0.006207</td>\n",
       "      <td>0.311056</td>\n",
       "      <td>0.339999</td>\n",
       "      <td>0.348945</td>\n",
       "      <td>0.000784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32.0</td>\n",
       "      <td>0.005809</td>\n",
       "      <td>0.320832</td>\n",
       "      <td>0.320002</td>\n",
       "      <td>0.359165</td>\n",
       "      <td>0.001001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0.006416</td>\n",
       "      <td>0.305980</td>\n",
       "      <td>0.349997</td>\n",
       "      <td>0.344023</td>\n",
       "      <td>0.001140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.005598</td>\n",
       "      <td>0.325590</td>\n",
       "      <td>0.310004</td>\n",
       "      <td>0.364406</td>\n",
       "      <td>0.001570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36.0</td>\n",
       "      <td>0.006633</td>\n",
       "      <td>0.301154</td>\n",
       "      <td>0.360005</td>\n",
       "      <td>0.338841</td>\n",
       "      <td>0.001777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.005391</td>\n",
       "      <td>0.330618</td>\n",
       "      <td>0.300006</td>\n",
       "      <td>0.369376</td>\n",
       "      <td>0.002417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>37.0</td>\n",
       "      <td>0.006838</td>\n",
       "      <td>0.296194</td>\n",
       "      <td>0.370003</td>\n",
       "      <td>0.333803</td>\n",
       "      <td>0.002724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>29.0</td>\n",
       "      <td>0.005195</td>\n",
       "      <td>0.335395</td>\n",
       "      <td>0.289998</td>\n",
       "      <td>0.374607</td>\n",
       "      <td>0.003586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>38.0</td>\n",
       "      <td>0.007040</td>\n",
       "      <td>0.291474</td>\n",
       "      <td>0.380002</td>\n",
       "      <td>0.328524</td>\n",
       "      <td>0.003953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   percentile  threshold  share_down  share_same  share_up  imbalance_score\n",
       "0        33.0   0.006007    0.315650    0.330001  0.354350         0.000765\n",
       "1        34.0   0.006207    0.311056    0.339999  0.348945         0.000784\n",
       "2        32.0   0.005809    0.320832    0.320002  0.359165         0.001001\n",
       "3        35.0   0.006416    0.305980    0.349997  0.344023         0.001140\n",
       "4        31.0   0.005598    0.325590    0.310004  0.364406         0.001570\n",
       "5        36.0   0.006633    0.301154    0.360005  0.338841         0.001777\n",
       "6        30.0   0.005391    0.330618    0.300006  0.369376         0.002417\n",
       "7        37.0   0.006838    0.296194    0.370003  0.333803         0.002724\n",
       "8        29.0   0.005195    0.335395    0.289998  0.374607         0.003586\n",
       "9        38.0   0.007040    0.291474    0.380002  0.328524         0.003953"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentile_grid = np.arange(10, 46, 1)\n",
    "best_thr, thr_grid = choose_balanced_symmetric_threshold(train_df[RETURN_COL], percentile_grid)\n",
    "print(f\"Selected threshold: ±{best_thr:.6f} ({best_thr*100:.3f}%)\")\n",
    "thr_grid.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(11, 5))\n",
    "ax.plot(thr_grid[\"percentile\"], thr_grid[\"share_down\"], label=\"Down share\", color=\"#d62728\", linewidth=2)\n",
    "ax.plot(thr_grid[\"percentile\"], thr_grid[\"share_same\"], label=\"Same share\", color=\"#1f77b4\", linewidth=2)\n",
    "ax.plot(thr_grid[\"percentile\"], thr_grid[\"share_up\"], label=\"Up share\", color=\"#2ca02c\", linewidth=2)\n",
    "ax.axhline(1/3, color=\"gray\", linestyle=\"--\", linewidth=1.2, label=\"Ideal 1/3\")\n",
    "best_row = thr_grid.iloc[0]\n",
    "ax.axvline(best_row[\"percentile\"], color=\"black\", linestyle=\":\", linewidth=1.8)\n",
    "ax.set_title(\"Class Balance vs Symmetric Threshold (Train)\", fontweight=\"bold\")\n",
    "ax.set_xlabel(\"Percentile of |Return|\")\n",
    "ax.set_ylabel(\"Class share\")\n",
    "ax.grid(alpha=0.25)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Build target and inspect class balance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panel[TARGET_COL] = make_return_status(panel[RETURN_COL], best_thr)\n",
    "\n",
    "train_df = panel[(panel[\"Date\"] >= TRAIN_START) & (panel[\"Date\"] <= TRAIN_END)].copy()\n",
    "val_df = panel[(panel[\"Date\"] >= VAL_START) & (panel[\"Date\"] <= VAL_END)].copy()\n",
    "\n",
    "train_counts = train_df[TARGET_COL].value_counts().reindex([\"down\", \"same\", \"up\"], fill_value=0)\n",
    "val_counts = val_df[TARGET_COL].value_counts().reindex([\"down\", \"same\", \"up\"], fill_value=0)\n",
    "\n",
    "display(pd.DataFrame({\n",
    "    \"train_count\": train_counts,\n",
    "    \"train_share\": train_counts / train_counts.sum(),\n",
    "    \"val_count\": val_counts,\n",
    "    \"val_share\": val_counts / val_counts.sum(),\n",
    "}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Prepare model data and preprocessing pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cols = [\"Date\", TARGET_COL] + NUMERIC_FEATURES + CATEGORICAL_FEATURES\n",
    "train_model = train_df[model_cols].dropna(subset=[TARGET_COL]).copy()\n",
    "val_model = val_df[model_cols].dropna(subset=[TARGET_COL]).copy()\n",
    "\n",
    "X_train = train_model[NUMERIC_FEATURES + CATEGORICAL_FEATURES].copy()\n",
    "y_train = train_model[TARGET_COL].copy()\n",
    "X_val = val_model[NUMERIC_FEATURES + CATEGORICAL_FEATURES].copy()\n",
    "y_val = val_model[TARGET_COL].copy()\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\n",
    "            \"num\",\n",
    "            Pipeline(\n",
    "                steps=[\n",
    "                    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "                    (\"scaler\", StandardScaler()),\n",
    "                ]\n",
    "            ),\n",
    "            NUMERIC_FEATURES,\n",
    "        ),\n",
    "        (\n",
    "            \"cat\",\n",
    "            Pipeline(\n",
    "                steps=[\n",
    "                    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                    (\"onehot\", _make_ohe()),\n",
    "                ]\n",
    "            ),\n",
    "            CATEGORICAL_FEATURES,\n",
    "        ),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape, \"| Validation:\", X_val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) TimeSeries CV (n_splits=5) to choose C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_rows = []\n",
    "\n",
    "X_train_ord = X_train.reset_index(drop=True)\n",
    "y_train_ord = y_train.reset_index(drop=True)\n",
    "dates_train_ord = train_model[\"Date\"].reset_index(drop=True)\n",
    "\n",
    "for C in C_GRID:\n",
    "    fold_acc = []\n",
    "    fold_f1 = []\n",
    "\n",
    "    for fold, tr_idx, te_idx in time_series_splits_by_date(dates_train_ord, n_splits=N_SPLITS):\n",
    "        X_tr, X_te = X_train_ord.iloc[tr_idx], X_train_ord.iloc[te_idx]\n",
    "        y_tr, y_te = y_train_ord.iloc[tr_idx], y_train_ord.iloc[te_idx]\n",
    "\n",
    "        clf = LogisticRegression(\n",
    "            penalty=\"l1\",\n",
    "            C=float(C),\n",
    "            solver=\"saga\",\n",
    "            multi_class=\"multinomial\",\n",
    "            max_iter=MAX_ITER,\n",
    "            n_jobs=-1,\n",
    "            random_state=RANDOM_STATE,\n",
    "        )\n",
    "        pipe = Pipeline(steps=[(\"preprocess\", preprocess), (\"model\", clf)])\n",
    "\n",
    "        pipe.fit(X_tr, y_tr)\n",
    "        pred = pipe.predict(X_te)\n",
    "\n",
    "        acc = accuracy_score(y_te, pred)\n",
    "        f1m = f1_score(y_te, pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "        fold_acc.append(acc)\n",
    "        fold_f1.append(f1m)\n",
    "        cv_rows.append({\"C\": float(C), \"fold\": fold, \"accuracy\": acc, \"f1_macro\": f1m})\n",
    "\n",
    "    print(f\"C={C:8.5f} | mean_acc={np.mean(fold_acc):.4f} | mean_f1_macro={np.mean(fold_f1):.4f}\")\n",
    "\n",
    "cv_detail = pd.DataFrame(cv_rows)\n",
    "cv_summary = (\n",
    "    cv_detail.groupby(\"C\", as_index=False)\n",
    "    .agg(\n",
    "        mean_accuracy=(\"accuracy\", \"mean\"),\n",
    "        std_accuracy=(\"accuracy\", \"std\"),\n",
    "        mean_f1_macro=(\"f1_macro\", \"mean\"),\n",
    "        std_f1_macro=(\"f1_macro\", \"std\"),\n",
    "    )\n",
    "    .sort_values([\"mean_f1_macro\", \"mean_accuracy\"], ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "best_C = float(cv_summary.loc[0, \"C\"])\n",
    "print(\"\\nSelected best C:\", best_C)\n",
    "display(cv_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9, 4.8))\n",
    "ax.plot(cv_summary[\"C\"], cv_summary[\"mean_f1_macro\"], marker=\"o\", linewidth=2, label=\"Mean CV Macro-F1\")\n",
    "ax.plot(cv_summary[\"C\"], cv_summary[\"mean_accuracy\"], marker=\"s\", linewidth=2, label=\"Mean CV Accuracy\")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.axvline(best_C, color=\"black\", linestyle=\":\", linewidth=1.5, label=f\"Selected C={best_C:.4g}\")\n",
    "ax.set_title(\"TimeSeries CV by C\", fontweight=\"bold\")\n",
    "ax.set_xlabel(\"C (log scale)\")\n",
    "ax.set_ylabel(\"Score\")\n",
    "ax.grid(alpha=0.25)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) Final model fit and evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocess\", preprocess),\n",
    "        (\n",
    "            \"model\",\n",
    "            LogisticRegression(\n",
    "                penalty=\"l1\",\n",
    "                C=best_C,\n",
    "                solver=\"saga\",\n",
    "                multi_class=\"multinomial\",\n",
    "                max_iter=MAX_ITER,\n",
    "                n_jobs=-1,\n",
    "                random_state=RANDOM_STATE,\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "pred_train = final_model.predict(X_train)\n",
    "pred_val = final_model.predict(X_val)\n",
    "\n",
    "metrics_train = metric_frame(y_train, pred_train, \"train\")\n",
    "metrics_val = metric_frame(y_val, pred_val, \"validation\")\n",
    "metrics_all = pd.concat([metrics_train, metrics_val], ignore_index=True)\n",
    "display(metrics_all)\n",
    "\n",
    "report_train = classification_report(y_train, pred_train, digits=4, zero_division=0)\n",
    "report_val = classification_report(y_val, pred_val, digits=4, zero_division=0)\n",
    "\n",
    "print(\"TRAIN report\\n\")\n",
    "print(report_train)\n",
    "print(\"\\nVALIDATION report\\n\")\n",
    "print(report_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"down\", \"same\", \"up\"]\n",
    "cm = confusion_matrix(y_val, pred_val, labels=labels)\n",
    "cm_norm = cm / cm.sum(axis=1, keepdims=True)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4.8))\n",
    "\n",
    "im0 = axes[0].imshow(cm, cmap=\"Blues\")\n",
    "axes[0].set_title(\"Validation CM (Counts)\", fontweight=\"bold\")\n",
    "axes[0].set_xticks(range(len(labels)))\n",
    "axes[0].set_yticks(range(len(labels)))\n",
    "axes[0].set_xticklabels(labels)\n",
    "axes[0].set_yticklabels(labels)\n",
    "axes[0].set_xlabel(\"Predicted\")\n",
    "axes[0].set_ylabel(\"Actual\")\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        axes[0].text(j, i, f\"{cm[i, j]}\", ha=\"center\", va=\"center\", color=\"black\")\n",
    "\n",
    "im1 = axes[1].imshow(cm_norm, cmap=\"Greens\", vmin=0, vmax=1)\n",
    "axes[1].set_title(\"Validation CM (Row %)\", fontweight=\"bold\")\n",
    "axes[1].set_xticks(range(len(labels)))\n",
    "axes[1].set_yticks(range(len(labels)))\n",
    "axes[1].set_xticklabels(labels)\n",
    "axes[1].set_yticklabels(labels)\n",
    "axes[1].set_xlabel(\"Predicted\")\n",
    "axes[1].set_ylabel(\"Actual\")\n",
    "for i in range(cm_norm.shape[0]):\n",
    "    for j in range(cm_norm.shape[1]):\n",
    "        axes[1].text(j, i, f\"{cm_norm[i, j]:.2%}\", ha=\"center\", va=\"center\", color=\"black\")\n",
    "\n",
    "fig.colorbar(im0, ax=axes[0], fraction=0.046, pad=0.04)\n",
    "fig.colorbar(im1, ax=axes[1], fraction=0.046, pad=0.04)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10) LASSO drivers and sector diagnostics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_fitted = final_model.named_steps[\"preprocess\"]\n",
    "clf_fitted = final_model.named_steps[\"model\"]\n",
    "\n",
    "feature_names_out = preprocess_fitted.get_feature_names_out()\n",
    "class_names = list(clf_fitted.classes_)\n",
    "\n",
    "coef_df = pd.DataFrame(\n",
    "    clf_fitted.coef_.T,\n",
    "    index=feature_names_out,\n",
    "    columns=[f\"coef_{c}\" for c in class_names],\n",
    ")\n",
    "coef_df[\"max_abs_coef\"] = coef_df.abs().max(axis=1)\n",
    "coef_df = coef_df.sort_values(\"max_abs_coef\", ascending=False)\n",
    "\n",
    "display(coef_df.head(25))\n",
    "\n",
    "top_n = 20\n",
    "plot_df = coef_df.head(top_n).iloc[::-1]\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "ax.barh(plot_df.index, plot_df[\"max_abs_coef\"], color=\"#4e79a7\")\n",
    "ax.set_title(f\"Top {top_n} Drivers by |Coefficient|\", fontweight=\"bold\")\n",
    "ax.set_xlabel(\"Max absolute coefficient\")\n",
    "ax.grid(axis=\"x\", alpha=0.2)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "proba_val = final_model.predict_proba(X_val)\n",
    "proba_cols = [f\"p_{c}\" for c in class_names]\n",
    "pred_val_df = val_model[[\"Date\", \"ticker\", \"sector\", RETURN_COL, TARGET_COL]].copy().reset_index(drop=True)\n",
    "pred_val_df[\"pred_status\"] = pred_val\n",
    "pred_val_df = pd.concat([pred_val_df, pd.DataFrame(proba_val, columns=proba_cols)], axis=1)\n",
    "\n",
    "sector_acc = (\n",
    "    pred_val_df.groupby(\"sector\", dropna=False)\n",
    "    .apply(lambda g: (g[TARGET_COL] == g[\"pred_status\"]).mean())\n",
    "    .reset_index(name=\"validation_accuracy\")\n",
    "    .sort_values(\"validation_accuracy\", ascending=False)\n",
    ")\n",
    "display(sector_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11) Save all outputs to `MultinomialLogit/`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thr_grid.to_csv(OUTPUT_DIR / \"threshold_grid_train_percentiles.csv\", index=False)\n",
    "cv_detail.to_csv(OUTPUT_DIR / \"cv_detail_by_fold.csv\", index=False)\n",
    "cv_summary.to_csv(OUTPUT_DIR / \"cv_summary_by_C.csv\", index=False)\n",
    "metrics_all.to_csv(OUTPUT_DIR / \"metrics_train_validation.csv\", index=False)\n",
    "coef_df.to_csv(OUTPUT_DIR / \"lasso_coefficients_full.csv\", index=True)\n",
    "pred_val_df.to_csv(OUTPUT_DIR / \"validation_predictions_with_probabilities.csv\", index=False)\n",
    "sector_acc.to_csv(OUTPUT_DIR / \"validation_accuracy_by_sector.csv\", index=False)\n",
    "\n",
    "labels = [\"down\", \"same\", \"up\"]\n",
    "cm = confusion_matrix(y_val, pred_val, labels=labels)\n",
    "cm_df = pd.DataFrame(cm, index=[f\"actual_{l}\" for l in labels], columns=[f\"pred_{l}\" for l in labels])\n",
    "cm_df.to_csv(OUTPUT_DIR / \"validation_confusion_matrix_counts.csv\", index=True)\n",
    "\n",
    "cm_norm = cm / cm.sum(axis=1, keepdims=True)\n",
    "cm_norm_df = pd.DataFrame(cm_norm, index=[f\"actual_{l}\" for l in labels], columns=[f\"pred_{l}\" for l in labels])\n",
    "cm_norm_df.to_csv(OUTPUT_DIR / \"validation_confusion_matrix_rowpct.csv\", index=True)\n",
    "\n",
    "(OUTPUT_DIR / \"classification_report_train.txt\").write_text(report_train, encoding=\"utf-8\")\n",
    "(OUTPUT_DIR / \"classification_report_validation.txt\").write_text(report_val, encoding=\"utf-8\")\n",
    "\n",
    "summary_lines = [\n",
    "    \"Multinomial Logit (LASSO) Panel Run Summary\",\n",
    "    f\"Run tag: {RUN_TAG}\",\n",
    "    f\"Date window: {START_DATE.date()} to {END_DATE.date()}\",\n",
    "    f\"Train window: {TRAIN_START.date()} to {TRAIN_END.date()}\",\n",
    "    f\"Validation window: {VAL_START.date()} to {VAL_END.date()}\",\n",
    "    f\"Selected threshold: ±{best_thr:.6f} ({best_thr*100:.3f}%)\",\n",
    "    f\"Selected C: {best_C}\",\n",
    "    \"\",\n",
    "    metrics_all.to_string(index=False),\n",
    "]\n",
    "(OUTPUT_DIR / \"run_summary.txt\").write_text(\"\\n\".join(summary_lines), encoding=\"utf-8\")\n",
    "\n",
    "print(\"Saved outputs to:\", OUTPUT_DIR)\n",
    "for p in sorted(OUTPUT_DIR.glob(\"*\")):\n",
    "    print(\" -\", p.name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "- This is a panel model with ticker + sector fixed effects (one-hot encoded).\n",
    "- Threshold is selected only from train data to avoid look-ahead bias.\n",
    "- Validation is strictly out-of-sample (last 2 months).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12) Load Existing Run Results (No Retraining)\n",
    "\n",
    "Use this section to inspect previously generated output folders (for example `smoke_test_10_tickers_*`, `smoke_test_50_tickers_*`, or full `run_*`) without re-running model training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "base = OUTPUT_BASE if 'OUTPUT_BASE' in globals() else Path.cwd() / 'MultinomialLogit'\n",
    "if not base.exists():\n",
    "    base = Path.cwd().parent / 'MultinomialLogit'\n",
    "\n",
    "folders = sorted([p for p in base.iterdir() if p.is_dir() and (p.name.startswith('run_') or p.name.startswith('smoke_test_'))])\n",
    "if not folders:\n",
    "    raise FileNotFoundError(f'No run folders found in {base}')\n",
    "\n",
    "for i, p in enumerate(folders, start=1):\n",
    "    print(f'{i:02d}. {p.name}')\n",
    "\n",
    "# Pick the latest by default; change the index manually if needed\n",
    "selected_run = folders[-1]\n",
    "print('\\nSelected run:', selected_run)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _safe_read_csv(path):\n",
    "    return pd.read_csv(path) if path.exists() else None\n",
    "\n",
    "files_to_check = [\n",
    "    'metrics_train_testing_validation.csv',\n",
    "    'metrics_train_validation.csv',\n",
    "    'cv_summary_by_C.csv',\n",
    "    'threshold_grid_train_percentiles.csv',\n",
    "    'testing_tscv_fold_metrics.csv',\n",
    "    'validation_accuracy_by_sector.csv',\n",
    "]\n",
    "\n",
    "loaded = {}\n",
    "for fn in files_to_check:\n",
    "    p = selected_run / fn\n",
    "    df = _safe_read_csv(p)\n",
    "    if df is not None:\n",
    "        loaded[fn] = df\n",
    "        print(f'Loaded: {fn} | shape={df.shape}')\n",
    "\n",
    "if 'metrics_train_testing_validation.csv' in loaded:\n",
    "    display(loaded['metrics_train_testing_validation.csv'])\n",
    "elif 'metrics_train_validation.csv' in loaded:\n",
    "    display(loaded['metrics_train_validation.csv'])\n",
    "\n",
    "if 'cv_summary_by_C.csv' in loaded:\n",
    "    display(loaded['cv_summary_by_C.csv'])\n",
    "\n",
    "if 'threshold_grid_train_percentiles.csv' in loaded:\n",
    "    display(loaded['threshold_grid_train_percentiles.csv'].head(10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}