{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Multinomial Logit (LASSO) on S&P 500 Panel Data\n",
        "\n",
        "This notebook builds a **panel dataset** (all S&P 500 firms together) and explains:\n",
        "- `up`\n",
        "- `same`\n",
        "- `down`\n",
        "\n",
        "for daily returns using **Multinomial Logistic Regression with L1 regularization (LASSO)**.\n",
        "\n",
        "## Workflow\n",
        "1. Append all `feature_datasets/*_features.csv` into panel data.\n",
        "2. Left join `stock_sectors.csv` and one-hot encode sector.\n",
        "3. Keep observations from **2024-11-01 to 2025-10-31**.\n",
        "4. Use **10 months for train/CV** and **last 2 months for out-of-sample validation**.\n",
        "5. Choose a symmetric threshold around zero based on train percentiles to balance classes.\n",
        "6. Train multinomial logit with LASSO using `TimeSeriesSplit(n_splits=5)`.\n",
        "7. Save metrics, predictions, coefficients, and plots to `MultinomialLogit/`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    balanced_accuracy_score,\n",
        "    f1_score,\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        ")\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "PROJECT_ROOT = Path.cwd()\n",
        "if not (PROJECT_ROOT / \"feature_datasets\").exists():\n",
        "    PROJECT_ROOT = PROJECT_ROOT.parent\n",
        "\n",
        "FEATURE_DIR = PROJECT_ROOT / \"feature_datasets\"\n",
        "SECTOR_PATH = PROJECT_ROOT / \"stock_sectors.csv\"\n",
        "OUTPUT_BASE = PROJECT_ROOT / \"MultinomialLogit\"\n",
        "\n",
        "START_DATE = pd.Timestamp(\"2024-11-01\")\n",
        "END_DATE = pd.Timestamp(\"2025-10-31\")\n",
        "TRAIN_START = pd.Timestamp(\"2024-11-01\")\n",
        "TRAIN_END = pd.Timestamp(\"2025-08-31\")\n",
        "VAL_START = pd.Timestamp(\"2025-09-01\")\n",
        "VAL_END = pd.Timestamp(\"2025-10-31\")\n",
        "\n",
        "NUMERIC_FEATURES = [\n",
        "    \"Return_Lag1\", \"Return_Lag2\", \"Return_Lag3\", \"Return_Lag5\", \"Return_Lag10\", \"Return_Lag20\",\n",
        "    \"Sentiment_Lag1\", \"Sentiment_Lag2\", \"Sentiment_Lag3\", \"Sentiment_Lag5\", \"Sentiment_Lag10\", \"Sentiment_Lag20\",\n",
        "    \"VIX_Lag1\", \"VIX_Lag2\", \"VIX_Lag3\", \"VIX_Lag5\", \"VIX_Lag10\", \"VIX_Lag20\",\n",
        "    \"roe\", \"roa\", \"op_margin\", \"debt_to_equity\", \"liquidity_ratio\", \"current_ratio\",\n",
        "    \"free_cf_margin\", \"revenue_growth\", \"ocf_to_assets\",\n",
        "    \"GDP_GDP_SA_PC_QOQ\", \"GDP_GDP_SA_PC_YOY\", \"GDP_GDP_NSA_PC_QOQ\", \"GDP_GDP_NSA_PC_YOY\",\n",
        "    \"IPI_IPI\", \"IPI_IPI_YOY\", \"IPI_IPI_QOQ\", \"IPI_IPI_SA\", \"IPI_IPI_SA_YOY\", \"IPI_IPI_SA_QOQ\",\n",
        "    \"UNEMP_UNRATE\", \"UNEMP_UNRATE_PC1\", \"UNEMP_UNRATE_PCH\",\n",
        "    \"UNEMP_UNRATENSA\", \"UNEMP_UNRATENSA_PC1\", \"UNEMP_UNRATENSA_PCH\",\n",
        "]\n",
        "\n",
        "CATEGORICAL_FEATURES = [\"ticker\", \"sector\"]  # ticker FE + sector FE\n",
        "TARGET_COL = \"Return_Status\"\n",
        "RETURN_COL = \"Return\"\n",
        "\n",
        "N_SPLITS = 5\n",
        "C_GRID = np.logspace(-2, 1.5, 8)\n",
        "MAX_ITER = 3000\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "RUN_TAG = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "OUTPUT_DIR = OUTPUT_BASE / f\"run_{RUN_TAG}\"\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"Project root:\", PROJECT_ROOT)\n",
        "print(\"Output dir:\", OUTPUT_DIR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Helper functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def _make_ohe():\n",
        "    try:\n",
        "        return OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True)\n",
        "    except TypeError:\n",
        "        return OneHotEncoder(handle_unknown=\"ignore\", sparse=True)\n",
        "\n",
        "\n",
        "def load_panel_feature_data(feature_dir: Path, required_cols: list[str]) -> pd.DataFrame:\n",
        "    files = sorted(feature_dir.glob(\"*_features.csv\"))\n",
        "    if not files:\n",
        "        raise FileNotFoundError(f\"No *_features.csv files in {feature_dir}\")\n",
        "\n",
        "    frames = []\n",
        "    needed = [\"Date\", RETURN_COL] + required_cols\n",
        "\n",
        "    for path in files:\n",
        "        ticker = path.name.replace(\"_features.csv\", \"\")\n",
        "        df = pd.read_csv(path)\n",
        "        missing = [c for c in needed if c not in df.columns]\n",
        "        if missing:\n",
        "            raise ValueError(f\"{path.name} missing columns: {missing}\")\n",
        "\n",
        "        tmp = df[needed].copy()\n",
        "        tmp[\"Date\"] = pd.to_datetime(tmp[\"Date\"], errors=\"coerce\")\n",
        "        tmp[\"ticker\"] = ticker\n",
        "        frames.append(tmp)\n",
        "\n",
        "    panel = pd.concat(frames, ignore_index=True)\n",
        "    panel = panel.dropna(subset=[\"Date\"])\n",
        "    return panel\n",
        "\n",
        "\n",
        "def make_return_status(ret: pd.Series, thr: float) -> pd.Series:\n",
        "    y = pd.Series(index=ret.index, dtype=\"object\")\n",
        "    y[ret > thr] = \"up\"\n",
        "    y[ret < -thr] = \"down\"\n",
        "    y[ret.between(-thr, thr, inclusive=\"both\")] = \"same\"\n",
        "    return y\n",
        "\n",
        "\n",
        "def choose_balanced_symmetric_threshold(train_returns: pd.Series, percentiles: np.ndarray):\n",
        "    train_returns = train_returns.dropna()\n",
        "    abs_ret = train_returns.abs()\n",
        "    rows = []\n",
        "\n",
        "    for p in percentiles:\n",
        "        thr = np.percentile(abs_ret, p)\n",
        "        labels = make_return_status(train_returns, thr)\n",
        "        share = labels.value_counts(normalize=True).reindex([\"down\", \"same\", \"up\"], fill_value=0.0)\n",
        "        imbalance = ((share - (1.0 / 3.0)) ** 2).sum()\n",
        "\n",
        "        rows.append(\n",
        "            {\n",
        "                \"percentile\": float(p),\n",
        "                \"threshold\": float(thr),\n",
        "                \"share_down\": float(share[\"down\"]),\n",
        "                \"share_same\": float(share[\"same\"]),\n",
        "                \"share_up\": float(share[\"up\"]),\n",
        "                \"imbalance_score\": float(imbalance),\n",
        "            }\n",
        "        )\n",
        "\n",
        "    grid_df = pd.DataFrame(rows).sort_values([\"imbalance_score\", \"percentile\"]).reset_index(drop=True)\n",
        "    best_thr = float(grid_df.loc[0, \"threshold\"])\n",
        "    return best_thr, grid_df\n",
        "\n",
        "\n",
        "def time_series_splits_by_date(dates: pd.Series, n_splits: int = 5):\n",
        "    d = pd.to_datetime(dates)\n",
        "    unique_dates = np.array(sorted(pd.Series(d.unique())))\n",
        "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
        "\n",
        "    for fold, (tr_d, te_d) in enumerate(tscv.split(unique_dates), start=1):\n",
        "        tr_dates = set(unique_dates[tr_d])\n",
        "        te_dates = set(unique_dates[te_d])\n",
        "\n",
        "        tr_idx = np.where(d.isin(tr_dates))[0]\n",
        "        te_idx = np.where(d.isin(te_dates))[0]\n",
        "        yield fold, tr_idx, te_idx\n",
        "\n",
        "\n",
        "def metric_frame(y_true, y_pred, split_name: str) -> pd.DataFrame:\n",
        "    return pd.DataFrame(\n",
        "        [\n",
        "            {\n",
        "                \"split\": split_name,\n",
        "                \"accuracy\": accuracy_score(y_true, y_pred),\n",
        "                \"balanced_accuracy\": balanced_accuracy_score(y_true, y_pred),\n",
        "                \"f1_macro\": f1_score(y_true, y_pred, average=\"macro\", zero_division=0),\n",
        "                \"f1_weighted\": f1_score(y_true, y_pred, average=\"weighted\", zero_division=0),\n",
        "                \"n_samples\": len(y_true),\n",
        "            }\n",
        "        ]\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Build panel + left join sectors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "panel = load_panel_feature_data(FEATURE_DIR, NUMERIC_FEATURES)\n",
        "sectors = pd.read_csv(SECTOR_PATH)[[\"ticker\", \"sector\"]].copy()\n",
        "panel = panel.merge(sectors, on=\"ticker\", how=\"left\")\n",
        "\n",
        "panel = panel[(panel[\"Date\"] >= START_DATE) & (panel[\"Date\"] <= END_DATE)].copy()\n",
        "panel = panel.sort_values([\"Date\", \"ticker\"]).reset_index(drop=True)\n",
        "\n",
        "print(\"Panel shape:\", panel.shape)\n",
        "print(\"Tickers:\", panel[\"ticker\"].nunique(), \"| Sectors:\", panel[\"sector\"].nunique())\n",
        "panel.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Time split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df = panel[(panel[\"Date\"] >= TRAIN_START) & (panel[\"Date\"] <= TRAIN_END)].copy()\n",
        "val_df = panel[(panel[\"Date\"] >= VAL_START) & (panel[\"Date\"] <= VAL_END)].copy()\n",
        "\n",
        "print(\"Train rows:\", len(train_df), \"|\", train_df[\"Date\"].min().date(), \"to\", train_df[\"Date\"].max().date())\n",
        "print(\"Val rows  :\", len(val_df), \"|\", val_df[\"Date\"].min().date(), \"to\", val_df[\"Date\"].max().date())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Symmetric threshold selection (train only)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "percentile_grid = np.arange(10, 46, 1)\n",
        "best_thr, thr_grid = choose_balanced_symmetric_threshold(train_df[RETURN_COL], percentile_grid)\n",
        "print(f\"Selected threshold: \u00b1{best_thr:.6f} ({best_thr*100:.3f}%)\")\n",
        "thr_grid.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(11, 5))\n",
        "ax.plot(thr_grid[\"percentile\"], thr_grid[\"share_down\"], label=\"Down share\", color=\"#d62728\", linewidth=2)\n",
        "ax.plot(thr_grid[\"percentile\"], thr_grid[\"share_same\"], label=\"Same share\", color=\"#1f77b4\", linewidth=2)\n",
        "ax.plot(thr_grid[\"percentile\"], thr_grid[\"share_up\"], label=\"Up share\", color=\"#2ca02c\", linewidth=2)\n",
        "ax.axhline(1/3, color=\"gray\", linestyle=\"--\", linewidth=1.2, label=\"Ideal 1/3\")\n",
        "best_row = thr_grid.iloc[0]\n",
        "ax.axvline(best_row[\"percentile\"], color=\"black\", linestyle=\":\", linewidth=1.8)\n",
        "ax.set_title(\"Class Balance vs Symmetric Threshold (Train)\", fontweight=\"bold\")\n",
        "ax.set_xlabel(\"Percentile of |Return|\")\n",
        "ax.set_ylabel(\"Class share\")\n",
        "ax.grid(alpha=0.25)\n",
        "ax.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Build target and inspect class balance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "panel[TARGET_COL] = make_return_status(panel[RETURN_COL], best_thr)\n",
        "\n",
        "train_df = panel[(panel[\"Date\"] >= TRAIN_START) & (panel[\"Date\"] <= TRAIN_END)].copy()\n",
        "val_df = panel[(panel[\"Date\"] >= VAL_START) & (panel[\"Date\"] <= VAL_END)].copy()\n",
        "\n",
        "train_counts = train_df[TARGET_COL].value_counts().reindex([\"down\", \"same\", \"up\"], fill_value=0)\n",
        "val_counts = val_df[TARGET_COL].value_counts().reindex([\"down\", \"same\", \"up\"], fill_value=0)\n",
        "\n",
        "display(pd.DataFrame({\n",
        "    \"train_count\": train_counts,\n",
        "    \"train_share\": train_counts / train_counts.sum(),\n",
        "    \"val_count\": val_counts,\n",
        "    \"val_share\": val_counts / val_counts.sum(),\n",
        "}))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Prepare model data and preprocessing pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_cols = [\"Date\", TARGET_COL] + NUMERIC_FEATURES + CATEGORICAL_FEATURES\n",
        "train_model = train_df[model_cols].dropna(subset=[TARGET_COL]).copy()\n",
        "val_model = val_df[model_cols].dropna(subset=[TARGET_COL]).copy()\n",
        "\n",
        "X_train = train_model[NUMERIC_FEATURES + CATEGORICAL_FEATURES].copy()\n",
        "y_train = train_model[TARGET_COL].copy()\n",
        "X_val = val_model[NUMERIC_FEATURES + CATEGORICAL_FEATURES].copy()\n",
        "y_val = val_model[TARGET_COL].copy()\n",
        "\n",
        "preprocess = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\n",
        "            \"num\",\n",
        "            Pipeline(\n",
        "                steps=[\n",
        "                    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "                    (\"scaler\", StandardScaler()),\n",
        "                ]\n",
        "            ),\n",
        "            NUMERIC_FEATURES,\n",
        "        ),\n",
        "        (\n",
        "            \"cat\",\n",
        "            Pipeline(\n",
        "                steps=[\n",
        "                    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "                    (\"onehot\", _make_ohe()),\n",
        "                ]\n",
        "            ),\n",
        "            CATEGORICAL_FEATURES,\n",
        "        ),\n",
        "    ],\n",
        "    remainder=\"drop\",\n",
        ")\n",
        "\n",
        "print(\"Train:\", X_train.shape, \"| Validation:\", X_val.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8) TimeSeries CV (n_splits=5) to choose C\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cv_rows = []\n",
        "\n",
        "X_train_ord = X_train.reset_index(drop=True)\n",
        "y_train_ord = y_train.reset_index(drop=True)\n",
        "dates_train_ord = train_model[\"Date\"].reset_index(drop=True)\n",
        "\n",
        "for C in C_GRID:\n",
        "    fold_acc = []\n",
        "    fold_f1 = []\n",
        "\n",
        "    for fold, tr_idx, te_idx in time_series_splits_by_date(dates_train_ord, n_splits=N_SPLITS):\n",
        "        X_tr, X_te = X_train_ord.iloc[tr_idx], X_train_ord.iloc[te_idx]\n",
        "        y_tr, y_te = y_train_ord.iloc[tr_idx], y_train_ord.iloc[te_idx]\n",
        "\n",
        "        clf = LogisticRegression(\n",
        "            penalty=\"l1\",\n",
        "            C=float(C),\n",
        "            solver=\"saga\",\n",
        "            multi_class=\"multinomial\",\n",
        "            max_iter=MAX_ITER,\n",
        "            n_jobs=-1,\n",
        "            random_state=RANDOM_STATE,\n",
        "        )\n",
        "        pipe = Pipeline(steps=[(\"preprocess\", preprocess), (\"model\", clf)])\n",
        "\n",
        "        pipe.fit(X_tr, y_tr)\n",
        "        pred = pipe.predict(X_te)\n",
        "\n",
        "        acc = accuracy_score(y_te, pred)\n",
        "        f1m = f1_score(y_te, pred, average=\"macro\", zero_division=0)\n",
        "\n",
        "        fold_acc.append(acc)\n",
        "        fold_f1.append(f1m)\n",
        "        cv_rows.append({\"C\": float(C), \"fold\": fold, \"accuracy\": acc, \"f1_macro\": f1m})\n",
        "\n",
        "    print(f\"C={C:8.5f} | mean_acc={np.mean(fold_acc):.4f} | mean_f1_macro={np.mean(fold_f1):.4f}\")\n",
        "\n",
        "cv_detail = pd.DataFrame(cv_rows)\n",
        "cv_summary = (\n",
        "    cv_detail.groupby(\"C\", as_index=False)\n",
        "    .agg(\n",
        "        mean_accuracy=(\"accuracy\", \"mean\"),\n",
        "        std_accuracy=(\"accuracy\", \"std\"),\n",
        "        mean_f1_macro=(\"f1_macro\", \"mean\"),\n",
        "        std_f1_macro=(\"f1_macro\", \"std\"),\n",
        "    )\n",
        "    .sort_values([\"mean_f1_macro\", \"mean_accuracy\"], ascending=False)\n",
        "    .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "best_C = float(cv_summary.loc[0, \"C\"])\n",
        "print(\"\\nSelected best C:\", best_C)\n",
        "display(cv_summary)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(9, 4.8))\n",
        "ax.plot(cv_summary[\"C\"], cv_summary[\"mean_f1_macro\"], marker=\"o\", linewidth=2, label=\"Mean CV Macro-F1\")\n",
        "ax.plot(cv_summary[\"C\"], cv_summary[\"mean_accuracy\"], marker=\"s\", linewidth=2, label=\"Mean CV Accuracy\")\n",
        "ax.set_xscale(\"log\")\n",
        "ax.axvline(best_C, color=\"black\", linestyle=\":\", linewidth=1.5, label=f\"Selected C={best_C:.4g}\")\n",
        "ax.set_title(\"TimeSeries CV by C\", fontweight=\"bold\")\n",
        "ax.set_xlabel(\"C (log scale)\")\n",
        "ax.set_ylabel(\"Score\")\n",
        "ax.grid(alpha=0.25)\n",
        "ax.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9) Final model fit and evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "final_model = Pipeline(\n",
        "    steps=[\n",
        "        (\"preprocess\", preprocess),\n",
        "        (\n",
        "            \"model\",\n",
        "            LogisticRegression(\n",
        "                penalty=\"l1\",\n",
        "                C=best_C,\n",
        "                solver=\"saga\",\n",
        "                multi_class=\"multinomial\",\n",
        "                max_iter=MAX_ITER,\n",
        "                n_jobs=-1,\n",
        "                random_state=RANDOM_STATE,\n",
        "            ),\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "final_model.fit(X_train, y_train)\n",
        "\n",
        "pred_train = final_model.predict(X_train)\n",
        "pred_val = final_model.predict(X_val)\n",
        "\n",
        "metrics_train = metric_frame(y_train, pred_train, \"train\")\n",
        "metrics_val = metric_frame(y_val, pred_val, \"validation\")\n",
        "metrics_all = pd.concat([metrics_train, metrics_val], ignore_index=True)\n",
        "display(metrics_all)\n",
        "\n",
        "report_train = classification_report(y_train, pred_train, digits=4, zero_division=0)\n",
        "report_val = classification_report(y_val, pred_val, digits=4, zero_division=0)\n",
        "\n",
        "print(\"TRAIN report\\n\")\n",
        "print(report_train)\n",
        "print(\"\\nVALIDATION report\\n\")\n",
        "print(report_val)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = [\"down\", \"same\", \"up\"]\n",
        "cm = confusion_matrix(y_val, pred_val, labels=labels)\n",
        "cm_norm = cm / cm.sum(axis=1, keepdims=True)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4.8))\n",
        "\n",
        "im0 = axes[0].imshow(cm, cmap=\"Blues\")\n",
        "axes[0].set_title(\"Validation CM (Counts)\", fontweight=\"bold\")\n",
        "axes[0].set_xticks(range(len(labels)))\n",
        "axes[0].set_yticks(range(len(labels)))\n",
        "axes[0].set_xticklabels(labels)\n",
        "axes[0].set_yticklabels(labels)\n",
        "axes[0].set_xlabel(\"Predicted\")\n",
        "axes[0].set_ylabel(\"Actual\")\n",
        "for i in range(cm.shape[0]):\n",
        "    for j in range(cm.shape[1]):\n",
        "        axes[0].text(j, i, f\"{cm[i, j]}\", ha=\"center\", va=\"center\", color=\"black\")\n",
        "\n",
        "im1 = axes[1].imshow(cm_norm, cmap=\"Greens\", vmin=0, vmax=1)\n",
        "axes[1].set_title(\"Validation CM (Row %)\", fontweight=\"bold\")\n",
        "axes[1].set_xticks(range(len(labels)))\n",
        "axes[1].set_yticks(range(len(labels)))\n",
        "axes[1].set_xticklabels(labels)\n",
        "axes[1].set_yticklabels(labels)\n",
        "axes[1].set_xlabel(\"Predicted\")\n",
        "axes[1].set_ylabel(\"Actual\")\n",
        "for i in range(cm_norm.shape[0]):\n",
        "    for j in range(cm_norm.shape[1]):\n",
        "        axes[1].text(j, i, f\"{cm_norm[i, j]:.2%}\", ha=\"center\", va=\"center\", color=\"black\")\n",
        "\n",
        "fig.colorbar(im0, ax=axes[0], fraction=0.046, pad=0.04)\n",
        "fig.colorbar(im1, ax=axes[1], fraction=0.046, pad=0.04)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10) LASSO drivers and sector diagnostics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "preprocess_fitted = final_model.named_steps[\"preprocess\"]\n",
        "clf_fitted = final_model.named_steps[\"model\"]\n",
        "\n",
        "feature_names_out = preprocess_fitted.get_feature_names_out()\n",
        "class_names = list(clf_fitted.classes_)\n",
        "\n",
        "coef_df = pd.DataFrame(\n",
        "    clf_fitted.coef_.T,\n",
        "    index=feature_names_out,\n",
        "    columns=[f\"coef_{c}\" for c in class_names],\n",
        ")\n",
        "coef_df[\"max_abs_coef\"] = coef_df.abs().max(axis=1)\n",
        "coef_df = coef_df.sort_values(\"max_abs_coef\", ascending=False)\n",
        "\n",
        "display(coef_df.head(25))\n",
        "\n",
        "top_n = 20\n",
        "plot_df = coef_df.head(top_n).iloc[::-1]\n",
        "fig, ax = plt.subplots(figsize=(10, 7))\n",
        "ax.barh(plot_df.index, plot_df[\"max_abs_coef\"], color=\"#4e79a7\")\n",
        "ax.set_title(f\"Top {top_n} Drivers by |Coefficient|\", fontweight=\"bold\")\n",
        "ax.set_xlabel(\"Max absolute coefficient\")\n",
        "ax.grid(axis=\"x\", alpha=0.2)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "proba_val = final_model.predict_proba(X_val)\n",
        "proba_cols = [f\"p_{c}\" for c in class_names]\n",
        "pred_val_df = val_model[[\"Date\", \"ticker\", \"sector\", RETURN_COL, TARGET_COL]].copy().reset_index(drop=True)\n",
        "pred_val_df[\"pred_status\"] = pred_val\n",
        "pred_val_df = pd.concat([pred_val_df, pd.DataFrame(proba_val, columns=proba_cols)], axis=1)\n",
        "\n",
        "sector_acc = (\n",
        "    pred_val_df.groupby(\"sector\", dropna=False)\n",
        "    .apply(lambda g: (g[TARGET_COL] == g[\"pred_status\"]).mean())\n",
        "    .reset_index(name=\"validation_accuracy\")\n",
        "    .sort_values(\"validation_accuracy\", ascending=False)\n",
        ")\n",
        "display(sector_acc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11) Save all outputs to `MultinomialLogit/`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "thr_grid.to_csv(OUTPUT_DIR / \"threshold_grid_train_percentiles.csv\", index=False)\n",
        "cv_detail.to_csv(OUTPUT_DIR / \"cv_detail_by_fold.csv\", index=False)\n",
        "cv_summary.to_csv(OUTPUT_DIR / \"cv_summary_by_C.csv\", index=False)\n",
        "metrics_all.to_csv(OUTPUT_DIR / \"metrics_train_validation.csv\", index=False)\n",
        "coef_df.to_csv(OUTPUT_DIR / \"lasso_coefficients_full.csv\", index=True)\n",
        "pred_val_df.to_csv(OUTPUT_DIR / \"validation_predictions_with_probabilities.csv\", index=False)\n",
        "sector_acc.to_csv(OUTPUT_DIR / \"validation_accuracy_by_sector.csv\", index=False)\n",
        "\n",
        "labels = [\"down\", \"same\", \"up\"]\n",
        "cm = confusion_matrix(y_val, pred_val, labels=labels)\n",
        "cm_df = pd.DataFrame(cm, index=[f\"actual_{l}\" for l in labels], columns=[f\"pred_{l}\" for l in labels])\n",
        "cm_df.to_csv(OUTPUT_DIR / \"validation_confusion_matrix_counts.csv\", index=True)\n",
        "\n",
        "cm_norm = cm / cm.sum(axis=1, keepdims=True)\n",
        "cm_norm_df = pd.DataFrame(cm_norm, index=[f\"actual_{l}\" for l in labels], columns=[f\"pred_{l}\" for l in labels])\n",
        "cm_norm_df.to_csv(OUTPUT_DIR / \"validation_confusion_matrix_rowpct.csv\", index=True)\n",
        "\n",
        "(OUTPUT_DIR / \"classification_report_train.txt\").write_text(report_train, encoding=\"utf-8\")\n",
        "(OUTPUT_DIR / \"classification_report_validation.txt\").write_text(report_val, encoding=\"utf-8\")\n",
        "\n",
        "summary_lines = [\n",
        "    \"Multinomial Logit (LASSO) Panel Run Summary\",\n",
        "    f\"Run tag: {RUN_TAG}\",\n",
        "    f\"Date window: {START_DATE.date()} to {END_DATE.date()}\",\n",
        "    f\"Train window: {TRAIN_START.date()} to {TRAIN_END.date()}\",\n",
        "    f\"Validation window: {VAL_START.date()} to {VAL_END.date()}\",\n",
        "    f\"Selected threshold: \u00b1{best_thr:.6f} ({best_thr*100:.3f}%)\",\n",
        "    f\"Selected C: {best_C}\",\n",
        "    \"\",\n",
        "    metrics_all.to_string(index=False),\n",
        "]\n",
        "(OUTPUT_DIR / \"run_summary.txt\").write_text(\"\\n\".join(summary_lines), encoding=\"utf-8\")\n",
        "\n",
        "print(\"Saved outputs to:\", OUTPUT_DIR)\n",
        "for p in sorted(OUTPUT_DIR.glob(\"*\")):\n",
        "    print(\" -\", p.name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Notes\n",
        "- This is a panel model with ticker + sector fixed effects (one-hot encoded).\n",
        "- Threshold is selected only from train data to avoid look-ahead bias.\n",
        "- Validation is strictly out-of-sample (last 2 months).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12) Load Existing Run Results (No Retraining)\n",
        "\n",
        "Use this section to inspect previously generated output folders (for example `smoke_test_10_tickers_*`, `smoke_test_50_tickers_*`, or full `run_*`) without re-running model training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "base = OUTPUT_BASE if 'OUTPUT_BASE' in globals() else Path.cwd() / 'MultinomialLogit'\n",
        "if not base.exists():\n",
        "    base = Path.cwd().parent / 'MultinomialLogit'\n",
        "\n",
        "folders = sorted([p for p in base.iterdir() if p.is_dir() and (p.name.startswith('run_') or p.name.startswith('smoke_test_'))])\n",
        "if not folders:\n",
        "    raise FileNotFoundError(f'No run folders found in {base}')\n",
        "\n",
        "for i, p in enumerate(folders, start=1):\n",
        "    print(f'{i:02d}. {p.name}')\n",
        "\n",
        "# Pick the latest by default; change the index manually if needed\n",
        "selected_run = folders[-1]\n",
        "print('\\nSelected run:', selected_run)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def _safe_read_csv(path):\n",
        "    return pd.read_csv(path) if path.exists() else None\n",
        "\n",
        "files_to_check = [\n",
        "    'metrics_train_testing_validation.csv',\n",
        "    'metrics_train_validation.csv',\n",
        "    'cv_summary_by_C.csv',\n",
        "    'threshold_grid_train_percentiles.csv',\n",
        "    'testing_tscv_fold_metrics.csv',\n",
        "    'validation_accuracy_by_sector.csv',\n",
        "]\n",
        "\n",
        "loaded = {}\n",
        "for fn in files_to_check:\n",
        "    p = selected_run / fn\n",
        "    df = _safe_read_csv(p)\n",
        "    if df is not None:\n",
        "        loaded[fn] = df\n",
        "        print(f'Loaded: {fn} | shape={df.shape}')\n",
        "\n",
        "if 'metrics_train_testing_validation.csv' in loaded:\n",
        "    display(loaded['metrics_train_testing_validation.csv'])\n",
        "elif 'metrics_train_validation.csv' in loaded:\n",
        "    display(loaded['metrics_train_validation.csv'])\n",
        "\n",
        "if 'cv_summary_by_C.csv' in loaded:\n",
        "    display(loaded['cv_summary_by_C.csv'])\n",
        "\n",
        "if 'threshold_grid_train_percentiles.csv' in loaded:\n",
        "    display(loaded['threshold_grid_train_percentiles.csv'].head(10))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}